{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d69bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports for artificial neural network\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "np.random.seed(42)  #Seed is necessary to ensure consistent replication of results\n",
    "\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d2ae053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    }
   ],
   "source": [
    "#Now build decision tree classifiers\n",
    "def data_info():\n",
    "    df.info()\n",
    "    null_counts = df.isnull().sum()\n",
    "    null_columns = null_counts[null_counts > 0]\n",
    "    return df.describe().transpose()\n",
    "\n",
    "df.isnull().sum().sum()\n",
    "\n",
    "Y=df[\"Bankrupt?\"]\n",
    "X=df.drop([\"Bankrupt?\"],axis=1)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(X,Y)\n",
    "\n",
    "importance_features = rf.feature_importances_\n",
    "important_features_df = pd.DataFrame({'Feature': X.columns, 'Importance': importance_features})\n",
    "important_features_df_desc =important_features_df.sort_values(by='Importance', ascending=False)\n",
    "important_features_df_asc =important_features_df.sort_values(by='Importance', ascending=True)\n",
    "important_features_df_desc.head(40)\n",
    "required = important_features_df_desc[important_features_df_desc.Importance>0.0105]\n",
    "required_features = df[required.Feature]  \n",
    "correlation_matrix = df.corr()\n",
    "target_corr = correlation_matrix[\"Bankrupt?\"].abs().sort_values(ascending=False)\n",
    "target_corr = target_corr.drop(\"Bankrupt?\")\n",
    "selected_features = target_corr[target_corr>=0.1]\n",
    "selected_columns = list(selected_features.index)\n",
    "df_selected = df[selected_columns]\n",
    "actual_corr = correlation_matrix[\"Bankrupt?\"][selected_features.index]\n",
    "positive_corr = actual_corr[actual_corr >= 0].sort_values(ascending=False)\n",
    "negative_corr = actual_corr[actual_corr < 0].sort_values(ascending=True)\n",
    "sorted_correlations = pd.concat([positive_corr, negative_corr])\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "selexted_X = df_selected\n",
    "selected_y = df[\"Bankrupt?\"]\n",
    "X_train,X_test,y_train,y_test = train_test_split(selexted_X,selected_y,test_size = 0.2,random_state=42)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\n",
    "    'max_depth': [2, 3, 5, 10, 20],\n",
    "    'min_samples_leaf': [10, 15, 20, 50, 100],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier(max_depth =5,min_samples_split = 20,random_state=42)\n",
    "grid_search_dt = GridSearchCV(estimator=dt_classifier, \n",
    "                           param_grid=params, \n",
    "                           cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n",
    "\n",
    "grid_search_dt.fit(X_train,y_train)\n",
    "\n",
    "grid_search_dt.best_estimator_\n",
    "\n",
    "best_dt = grid_search_dt.best_estimator_\n",
    "\n",
    "dt_train_pred = best_dt.predict(X_train)\n",
    "dt_test_pred = best_dt.predict(X_test)\n",
    "\n",
    "tree_info = best_dt.tree_\n",
    "num_nodes = tree_info.node_count\n",
    "num_leaves = tree_info.n_leaves\n",
    "num_decision = num_nodes - num_leaves\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "grid_search_rf = GridSearchCV(estimator=rf_classifier, \n",
    "                           param_grid=params, \n",
    "                           cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n",
    "\n",
    "grid_search_rf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "grid_search_rf.best_estimator_\n",
    "\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "y_train_pred = best_rf.predict(X_train)\n",
    "y_test_pred = best_rf.predict(X_test)\n",
    "\n",
    "#Classifier 3\n",
    "classifier1 = pd.DataFrame(y_train_pred, index=X_train.index, columns=['Random Forest'])\n",
    "#np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "#print('Classifier 1: ', classifier1)\n",
    "#print('Classifier 3: ', classifier3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399e8db4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryan\\AppData\\Local\\Temp\\ipykernel_9256\\2061690676.py:15: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_val = pd.Series(index = features_left)\n",
      "Processing Columns: 100%|█████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 323.24it/s]\n"
     ]
    }
   ],
   "source": [
    "#Additional imports for linear regression model\n",
    "import statsmodels.api as sm\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "target = 'Bankrupt?'\n",
    "predictors = [col for col in df.columns if col != target]\n",
    "\n",
    "#forward selection\n",
    "def forward_selection (df, target, predictors):\n",
    "    features = []\n",
    "    best_features = []\n",
    "    while True: \n",
    "        features_left = list(set(predictors) - set(features))\n",
    "        new_val = pd.Series(index = features_left)\n",
    "        for new_col in tqdm(features_left, desc=\"Processing Columns\"):\n",
    "            model = sm.OLS(df[target], sm.add_constant(df[features + [new_col]])).fit()\n",
    "            new_val[new_col] = model.pvalues[new_col]\n",
    "        min_p_value = new_val.min()\n",
    "        if min_p_value < 0.05:\n",
    "            best_feature = new_val.idxmin()\n",
    "            features.append(best_feature)\n",
    "            best_features.append(best_feature)\n",
    "        else:\n",
    "            break\n",
    "        return best_features\n",
    "\n",
    "best_predictors = forward_selection(df, target, list(X_train.columns))\n",
    "\n",
    "final_model = sm.OLS(y_train, sm.add_constant(X_train[best_predictors])).fit()\n",
    "\n",
    "#find accuracy \n",
    "linRegPred = final_model.predict(sm.add_constant(X_train[best_predictors]))\n",
    "\n",
    "#Classifier 2\n",
    "classifier2 = pd.DataFrame(linRegPred, columns=['linear Regression'])\n",
    "\n",
    "assert classifier1.index.equals(classifier2.index), \"Indices do not match!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "775858df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we get the classifier for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dedf31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier1:        Random Forest\n",
      "3759              0\n",
      "1782              0\n",
      "5013              0\n",
      "5412              0\n",
      "3066              0\n",
      "...             ...\n",
      "3772              0\n",
      "5191              0\n",
      "5226              0\n",
      "5390              0\n",
      "860               0\n",
      "\n",
      "[5455 rows x 1 columns]\n",
      "classifier2:        linear Regression\n",
      "3759           0.039881\n",
      "1782           0.027167\n",
      "5013           0.028720\n",
      "5412           0.028267\n",
      "3066           0.035477\n",
      "...                 ...\n",
      "3772          -0.006723\n",
      "5191          -0.016226\n",
      "5226           0.024276\n",
      "5390          -0.032160\n",
      "860           -0.024261\n",
      "\n",
      "[5455 rows x 1 columns]\n",
      "classifier3:        Logistic Regression\n",
      "3759                    0\n",
      "1782                    0\n",
      "5013                    0\n",
      "5412                    0\n",
      "3066                    0\n",
      "...                   ...\n",
      "3772                    0\n",
      "5191                    0\n",
      "5226                    0\n",
      "5390                    0\n",
      "860                     0\n",
      "\n",
      "[5455 rows x 1 columns]\n",
      "      Random Forest  linear Regression  Logistic Regression\n",
      "3759              0           0.039881                    0\n",
      "1782              0           0.027167                    0\n",
      "5013              0           0.028720                    0\n",
      "5412              0           0.028267                    0\n",
      "3066              0           0.035477                    0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "#data = pd.read_csv(\"/Users/ambrasina/Downloads/data3.csv\")\n",
    "\n",
    "# Define the features (X) and the target (y)\n",
    "#X = data.drop(columns=['Bankrupt?'])\n",
    "#y = data['Bankrupt?']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the logistic regression model with class_weight='balanced'\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "classifier3 = pd.DataFrame(model.predict(X_train), index=X_train.index, columns=['Logistic Regression'])\n",
    "\n",
    "print('classifier1: ', classifier1)\n",
    "print('classifier2: ', classifier2)\n",
    "print('classifier3: ', classifier3)\n",
    "\n",
    "assert classifier3.index.equals(classifier2.index), \"Indices do not match!\"\n",
    "\n",
    "combined_df = pd.concat([classifier1, classifier2, classifier3], axis=1)\n",
    "\n",
    "print(combined_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
