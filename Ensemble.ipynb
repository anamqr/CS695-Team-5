{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d69bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports for artificial neural network\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "np.random.seed(42)  #Seed is necessary to ensure consistent replication of results\n",
    "\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5025a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    }
   ],
   "source": [
    "#Now build decision tree classifiers\n",
    "def data_info():\n",
    "    df.info()\n",
    "    null_counts = df.isnull().sum()\n",
    "    null_columns = null_counts[null_counts > 0]\n",
    "    return df.describe().transpose()\n",
    "\n",
    "df.isnull().sum().sum()\n",
    "\n",
    "Y=df[\"Bankrupt?\"]\n",
    "X=df.drop([\"Bankrupt?\"],axis=1)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(X,Y)\n",
    "\n",
    "importance_features = rf.feature_importances_\n",
    "important_features_df = pd.DataFrame({'Feature': X.columns, 'Importance': importance_features})\n",
    "important_features_df_desc =important_features_df.sort_values(by='Importance', ascending=False)\n",
    "important_features_df_asc =important_features_df.sort_values(by='Importance', ascending=True)\n",
    "important_features_df_desc.head(40)\n",
    "required = important_features_df_desc[important_features_df_desc.Importance>0.0105]\n",
    "required_features = df[required.Feature]  \n",
    "correlation_matrix = df.corr()\n",
    "target_corr = correlation_matrix[\"Bankrupt?\"].abs().sort_values(ascending=False)\n",
    "target_corr = target_corr.drop(\"Bankrupt?\")\n",
    "selected_features = target_corr[target_corr>=0.1]\n",
    "selected_columns = list(selected_features.index)\n",
    "df_selected = df[selected_columns]\n",
    "actual_corr = correlation_matrix[\"Bankrupt?\"][selected_features.index]\n",
    "positive_corr = actual_corr[actual_corr >= 0].sort_values(ascending=False)\n",
    "negative_corr = actual_corr[actual_corr < 0].sort_values(ascending=True)\n",
    "sorted_correlations = pd.concat([positive_corr, negative_corr])\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "selexted_X = df_selected\n",
    "selected_y = df[\"Bankrupt?\"]\n",
    "X_train,X_test,y_train,y_test = train_test_split(selexted_X,selected_y,test_size = 0.2,random_state=42)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\n",
    "    'max_depth': [2, 3, 5, 10, 20],\n",
    "    'min_samples_leaf': [10, 15, 20, 50, 100],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier(max_depth =5,min_samples_split = 20,random_state=42)\n",
    "grid_search_dt = GridSearchCV(estimator=dt_classifier, \n",
    "                           param_grid=params, \n",
    "                           cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n",
    "\n",
    "grid_search_dt.fit(X_train,y_train)\n",
    "\n",
    "grid_search_dt.best_estimator_\n",
    "\n",
    "best_dt = grid_search_dt.best_estimator_\n",
    "\n",
    "dt_train_pred = best_dt.predict(X_train)\n",
    "dt_test_pred = best_dt.predict(X_test)\n",
    "\n",
    "tree_info = best_dt.tree_\n",
    "num_nodes = tree_info.node_count\n",
    "num_leaves = tree_info.n_leaves\n",
    "num_decision = num_nodes - num_leaves\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "grid_search_rf = GridSearchCV(estimator=rf_classifier, \n",
    "                           param_grid=params, \n",
    "                           cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n",
    "\n",
    "grid_search_rf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "grid_search_rf.best_estimator_\n",
    "\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "y_train_pred = best_rf.predict(X_train)\n",
    "y_test_pred = best_rf.predict(X_test)\n",
    "\n",
    "#Classifier 1\n",
    "classifier1 = pd.DataFrame(y_train_pred, index=X_train.index, columns=['Random Forest'])\n",
    "\n",
    "#classifier 1a\n",
    "classifier1a = pd.DataFrame(y_test_pred, index=X_test.index, columns=['Random Forest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "918efd32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryan\\AppData\\Local\\Temp\\ipykernel_1012\\3779582531.py:15: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_val = pd.Series(index = features_left)\n",
      "Processing Columns: 100%|█████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 340.42it/s]\n"
     ]
    }
   ],
   "source": [
    "#Additional imports for linear regression model\n",
    "import statsmodels.api as sm\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "target = 'Bankrupt?'\n",
    "predictors = [col for col in df.columns if col != target]\n",
    "\n",
    "#forward selection\n",
    "def forward_selection (df, target, predictors):\n",
    "    features = []\n",
    "    best_features = []\n",
    "    while True: \n",
    "        features_left = list(set(predictors) - set(features))\n",
    "        new_val = pd.Series(index = features_left)\n",
    "        for new_col in tqdm(features_left, desc=\"Processing Columns\"):\n",
    "            model = sm.OLS(df[target], sm.add_constant(df[features + [new_col]])).fit()\n",
    "            new_val[new_col] = model.pvalues[new_col]\n",
    "        min_p_value = new_val.min()\n",
    "        if min_p_value < 0.05:\n",
    "            best_feature = new_val.idxmin()\n",
    "            features.append(best_feature)\n",
    "            best_features.append(best_feature)\n",
    "        else:\n",
    "            break\n",
    "        return best_features\n",
    "\n",
    "best_predictors = forward_selection(df, target, list(X_train.columns))\n",
    "\n",
    "final_model = sm.OLS(y_train, sm.add_constant(X_train[best_predictors])).fit()\n",
    "\n",
    "#find accuracy \n",
    "linRegPred = final_model.predict(sm.add_constant(X_train[best_predictors]))\n",
    "\n",
    "#Classifier 2\n",
    "classifier2 = pd.DataFrame(linRegPred, columns=['linear Regression'])\n",
    "\n",
    "classifier2a = pd.DataFrame(final_model.predict(sm.add_constant(X_test[best_predictors])), columns=['linear Regression'])\n",
    "\n",
    "assert classifier1.index.equals(classifier2.index), \"Indices do not match!\"\n",
    "\n",
    "assert classifier1a.index.equals(classifier2a.index), \"Indices do not match!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c74c247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns = X_train.columns.str.strip()\n",
    "X_test.columns = X_test.columns.str.strip()\n",
    "\n",
    "feature = 'Net Income to Total Assets'\n",
    "\n",
    "x = X_train[[feature]]\n",
    "xtest = X_test[[feature]]\n",
    "y = y_train\n",
    "ytest = y_test\n",
    "\n",
    "x = sm.add_constant(x)\n",
    "xtest = sm.add_constant(xtest)\n",
    "final_model = sm.OLS(y, x).fit()\n",
    "\n",
    "predictions = final_model.predict(x)\n",
    "\n",
    "#Classifier 3\n",
    "classifier3 = pd.DataFrame(predictions, columns=['linear Regression 2'])\n",
    "\n",
    "classifier3a = pd.DataFrame(final_model.predict(xtest), columns=['linear Regression 2'])\n",
    "\n",
    "assert classifier2.index.equals(classifier3.index), \"Indices do not match!\"\n",
    "\n",
    "assert classifier2a.index.equals(classifier3a.index), \"Indices do not match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03f045d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we get the classifier for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2399a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "classifier4 = pd.DataFrame(model.predict(X_train), index=X_train.index, columns=['Logistic Regression'])\n",
    "\n",
    "classifier4a = pd.DataFrame(model.predict(X_test), index=X_test.index, columns=['Logistic Regression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fc61a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryan\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryan\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Imports for support vector machine\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df['Bankrupt?'] = pd.Categorical(df['Bankrupt?'])\n",
    "\n",
    "dependentVariable = ['Bankrupt?']\n",
    "\n",
    "featureGroupA = [\n",
    "    'Tax rate (A)',\n",
    "    'Net Value Per Share (B)',\n",
    "    'Net Value Per Share (A)',\n",
    "    'Net Value Per Share (C)',\n",
    "    'Persistent EPS in the Last Four Seasons',\n",
    "    'Operating Profit Per Share (Yuan ¥)',\n",
    "    'Per Share Net profit before tax (Yuan ¥)',\n",
    "    'Debt ratio %',\n",
    "    'Operating profit/Paid-in capital',\n",
    "    'Net profit before tax/Paid-in capital',\n",
    "    'Quick Assets/Total Assets',\n",
    "    'Cash/Total Assets',\n",
    "    'Current Liability to Assets',\n",
    "    'Total expense/Assets',\n",
    "    'Equity to Long-term Liability',\n",
    "    'Liability-Assets Flag',\n",
    "    'Equity to Liability'\n",
    "    ]\n",
    "\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "independentVariablesA = [col.lower() for col in featureGroupA]\n",
    "\n",
    "df['independentVariableA'] = df[independentVariablesA].mean(axis=1)\n",
    "\n",
    "featureGroupB = [\n",
    "    'Operating Gross Margin',\n",
    "    'Realized Sales Gross Margin',\n",
    "    'Net worth/Assets',\n",
    "    'Working Capital to Total Assets',\n",
    "    'Working Capital/Equity',\n",
    "    'Retained Earnings to Total Assets',\n",
    "    'Current Liability to Current Assets',\n",
    "    'Net Income to Total Assets',\n",
    "    'Gross Profit to Sales',\n",
    "    'Net Income to Stockholder\\'s Equity'\n",
    "]\n",
    "\n",
    "independentVariablesB = [col.lower() for col in featureGroupB]\n",
    "df['independentVariableB'] = df[independentVariablesB].mean(axis=1)\n",
    "\n",
    "featureGroupC = [\n",
    "    'CFO to Assets',\n",
    "    'Borrowing dependency',\n",
    "    'Operating profit per person',\n",
    "    'ROA(A) before interest and % after tax',\n",
    "    'ROA(B) before interest and depreciation after tax',\n",
    "    'ROA(C) before interest and depreciation before interest',\n",
    "    'Current Liabilities/Equity',\n",
    "    'Current Liability to Equity',\n",
    "    'Liability to Equity'\n",
    "]\n",
    "\n",
    "independentVariablesC = [col.lower() for col in featureGroupC]\n",
    "df['independentVariableC'] = df[independentVariablesC].mean(axis=1)\n",
    "\n",
    "dependentVariable = [col.lower() for col in dependentVariable]\n",
    "\n",
    "X = df[['independentVariableA', 'independentVariableB', 'independentVariableC']]\n",
    "\n",
    "Y = df[dependentVariable]\n",
    "\n",
    "Y = Y.values.ravel()\n",
    "\n",
    "#In order to match instances with the currently in use X_train data, we grab the indices\n",
    "trainIndices = X_train.index\n",
    "#Same with the test data\n",
    "testIndices = X_test.index\n",
    "trainX = X.loc[trainIndices]\n",
    "trainY = Y[trainIndices]\n",
    "testX = X.drop(trainIndices)\n",
    "testY = np.delete(Y, trainIndices)\n",
    "\n",
    "polynomial_svm_clf = Pipeline([\n",
    "    (\"poly_features\", PolynomialFeatures(degree=3)),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm_clf\", svm.LinearSVC(C=100000, loss=\"squared_hinge\", max_iter=10000))\n",
    "])\n",
    "\n",
    "polynomial_svm_clf.fit(trainX, trainY)\n",
    "\n",
    "polynomial_svm_clf2 = Pipeline([\n",
    "    (\"poly_features\", PolynomialFeatures(degree=15)),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm_clf\", svm.LinearSVC(C=1000, loss=\"hinge\", max_iter=1000))\n",
    "])\n",
    "\n",
    "polynomial_svm_clf2.fit(trainX, trainY)\n",
    "\n",
    "print('Evaluation: ')\n",
    "trainPredictions = polynomial_svm_clf.predict(trainX)\n",
    "#Classifier 5\n",
    "classifier5 = pd.DataFrame(trainPredictions, index=X_train.index, columns=['Support Vector Machine 1'])\n",
    "\n",
    "\n",
    "testPredictions = polynomial_svm_clf.predict(testX)\n",
    "classifier5a = pd.DataFrame(testPredictions, index=X_test.index, columns=['Support Vector Machine 1'])\n",
    "\n",
    "trainPredictions2 = polynomial_svm_clf2.predict(trainX)\n",
    "#Classifier 6\n",
    "classifier6 = pd.DataFrame(trainPredictions2, index=X_train.index, columns=['Support Vector Machine 2'])\n",
    "\n",
    "testPredictions2 = polynomial_svm_clf2.predict(testX)\n",
    "classifier6a = pd.DataFrame(testPredictions2, index=X_test.index, columns=['Support Vector Machine 2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf030d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier1:        Random Forest\n",
      "3759              0\n",
      "1782              0\n",
      "5013              0\n",
      "5412              0\n",
      "3066              0\n",
      "...             ...\n",
      "3772              0\n",
      "5191              0\n",
      "5226              0\n",
      "5390              0\n",
      "860               0\n",
      "\n",
      "[5455 rows x 1 columns]\n",
      "classifier2:        linear Regression\n",
      "3759           0.039881\n",
      "1782           0.027167\n",
      "5013           0.028720\n",
      "5412           0.028267\n",
      "3066           0.035477\n",
      "...                 ...\n",
      "3772          -0.006723\n",
      "5191          -0.016226\n",
      "5226           0.024276\n",
      "5390          -0.032160\n",
      "860           -0.024261\n",
      "\n",
      "[5455 rows x 1 columns]\n",
      "classifier3:        linear Regression 2\n",
      "3759             0.039881\n",
      "1782             0.027167\n",
      "5013             0.028720\n",
      "5412             0.028267\n",
      "3066             0.035477\n",
      "...                   ...\n",
      "3772            -0.006723\n",
      "5191            -0.016226\n",
      "5226             0.024276\n",
      "5390            -0.032160\n",
      "860             -0.024261\n",
      "\n",
      "[5455 rows x 1 columns]\n",
      "classifier4:        Logistic Regression\n",
      "3759                    0\n",
      "1782                    0\n",
      "5013                    0\n",
      "5412                    0\n",
      "3066                    0\n",
      "...                   ...\n",
      "3772                    0\n",
      "5191                    0\n",
      "5226                    0\n",
      "5390                    0\n",
      "860                     0\n",
      "\n",
      "[5455 rows x 1 columns]\n",
      "classifier5:        Support Vector Machine 1\n",
      "3759                         0\n",
      "1782                         0\n",
      "5013                         0\n",
      "5412                         0\n",
      "3066                         0\n",
      "...                        ...\n",
      "3772                         0\n",
      "5191                         0\n",
      "5226                         0\n",
      "5390                         0\n",
      "860                          0\n",
      "\n",
      "[5455 rows x 1 columns]\n",
      "classifier6:        Support Vector Machine 2\n",
      "3759                         0\n",
      "1782                         0\n",
      "5013                         0\n",
      "5412                         0\n",
      "3066                         0\n",
      "...                        ...\n",
      "3772                         0\n",
      "5191                         0\n",
      "5226                         0\n",
      "5390                         0\n",
      "860                          0\n",
      "\n",
      "[5455 rows x 1 columns]\n",
      "classifier1a:        Random Forest\n",
      "239               0\n",
      "2850              0\n",
      "2687              0\n",
      "6500              0\n",
      "2684              0\n",
      "...             ...\n",
      "1357              0\n",
      "3946              0\n",
      "5491              0\n",
      "2112              0\n",
      "6423              0\n",
      "\n",
      "[1364 rows x 1 columns]\n",
      "classifier2a:        linear Regression\n",
      "239            0.087525\n",
      "2850           0.018050\n",
      "2687          -0.021308\n",
      "6500           0.084461\n",
      "2684           0.027854\n",
      "...                 ...\n",
      "1357           0.025791\n",
      "3946           0.025537\n",
      "5491           0.046093\n",
      "2112           0.057831\n",
      "6423          -0.009602\n",
      "\n",
      "[1364 rows x 1 columns]\n",
      "classifier3a:        linear Regression 2\n",
      "239              0.087525\n",
      "2850             0.018050\n",
      "2687            -0.021308\n",
      "6500             0.084461\n",
      "2684             0.027854\n",
      "...                   ...\n",
      "1357             0.025791\n",
      "3946             0.025537\n",
      "5491             0.046093\n",
      "2112             0.057831\n",
      "6423            -0.009602\n",
      "\n",
      "[1364 rows x 1 columns]\n",
      "classifier4a:        Logistic Regression\n",
      "239                     0\n",
      "2850                    0\n",
      "2687                    0\n",
      "6500                    1\n",
      "2684                    0\n",
      "...                   ...\n",
      "1357                    0\n",
      "3946                    0\n",
      "5491                    1\n",
      "2112                    1\n",
      "6423                    0\n",
      "\n",
      "[1364 rows x 1 columns]\n",
      "classifier5a:        Support Vector Machine 1\n",
      "239                          0\n",
      "2850                         0\n",
      "2687                         0\n",
      "6500                         0\n",
      "2684                         0\n",
      "...                        ...\n",
      "1357                         0\n",
      "3946                         0\n",
      "5491                         0\n",
      "2112                         0\n",
      "6423                         0\n",
      "\n",
      "[1364 rows x 1 columns]\n",
      "classifier6a:        Support Vector Machine 2\n",
      "239                          0\n",
      "2850                         0\n",
      "2687                         0\n",
      "6500                         0\n",
      "2684                         0\n",
      "...                        ...\n",
      "1357                         0\n",
      "3946                         0\n",
      "5491                         0\n",
      "2112                         0\n",
      "6423                         0\n",
      "\n",
      "[1364 rows x 1 columns]\n",
      "      Random Forest  linear Regression  linear Regression 2  \\\n",
      "3759              0           0.039881             0.039881   \n",
      "1782              0           0.027167             0.027167   \n",
      "5013              0           0.028720             0.028720   \n",
      "5412              0           0.028267             0.028267   \n",
      "3066              0           0.035477             0.035477   \n",
      "\n",
      "      Logistic Regression  Support Vector Machine 1  Support Vector Machine 2  \n",
      "3759                    0                         0                         0  \n",
      "1782                    0                         0                         0  \n",
      "5013                    0                         0                         0  \n",
      "5412                    0                         0                         0  \n",
      "3066                    0                         0                         0  \n",
      "      Random Forest  linear Regression  linear Regression 2  \\\n",
      "239               0           0.087525             0.087525   \n",
      "2850              0           0.018050             0.018050   \n",
      "2687              0          -0.021308            -0.021308   \n",
      "6500              0           0.084461             0.084461   \n",
      "2684              0           0.027854             0.027854   \n",
      "\n",
      "      Logistic Regression  Support Vector Machine 1  Support Vector Machine 2  \n",
      "239                     0                         0                         0  \n",
      "2850                    0                         0                         0  \n",
      "2687                    0                         0                         0  \n",
      "6500                    1                         0                         0  \n",
      "2684                    0                         0                         0  \n"
     ]
    }
   ],
   "source": [
    "print('classifier1: ', classifier1)\n",
    "print('classifier2: ', classifier2)\n",
    "print('classifier3: ', classifier3)\n",
    "print('classifier4: ', classifier4)\n",
    "print('classifier5: ', classifier5)\n",
    "print('classifier6: ', classifier6)\n",
    "\n",
    "assert classifier3.index.equals(classifier2.index), \"Indices do not match!\"\n",
    "assert classifier4.index.equals(classifier3.index), \"Indices do not match!\"\n",
    "assert classifier5.index.equals(classifier4.index), \"Indices do not match!\"\n",
    "assert classifier6.index.equals(classifier5.index), \"Indices do not match!\"\n",
    "\n",
    "print('classifier1a: ', classifier1a)\n",
    "print('classifier2a: ', classifier2a)\n",
    "print('classifier3a: ', classifier3a)\n",
    "print('classifier4a: ', classifier4a)\n",
    "print('classifier5a: ', classifier5a)\n",
    "print('classifier6a: ', classifier6a)\n",
    "\n",
    "assert classifier3a.index.equals(classifier2a.index), \"Indices do not match!\"\n",
    "assert classifier4a.index.equals(classifier3a.index), \"Indices do not match!\"\n",
    "assert classifier5a.index.equals(classifier4a.index), \"Indices do not match!\"\n",
    "assert classifier6a.index.equals(classifier5a.index), \"Indices do not match!\"\n",
    "\n",
    "train_df = pd.concat([classifier1, classifier2, classifier3, classifier4, classifier5, classifier6], axis=1)\n",
    "test_df = pd.concat([classifier1a, classifier2a, classifier3a, classifier4a, classifier5a, classifier6a], axis=1)\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
